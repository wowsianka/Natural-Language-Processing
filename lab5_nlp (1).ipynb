{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emeZZJF2DhOK",
        "outputId": "121d6939-1d05-49a9-b9d5-8d2e74baa651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCE1KYsKDePN"
      },
      "outputs": [],
      "source": [
        "import transformers \n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polbert - Polish BERT\n",
        "Polish version of BERT language model is here! It is now available in two variants: cased and uncased, both can be downloaded and used via HuggingFace transformers library. I recommend using the cased model, more info on the differences and benchmark results below.\n",
        "\n"
      ],
      "metadata": {
        "id": "3nOhxW7CMppL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
        "model_bert = BertForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")\n",
        "tokenizer_bert = BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybe7Zn2YF8hz",
        "outputId": "28680694-eb01-4cfb-aa6a-4c39e895bd5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dkleczek/bert-base-polish-cased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_predict(sentance):\n",
        "    nlp = pipeline('fill-mask', model=model_bert, tokenizer=tokenizer_bert)\n",
        "    first_part = sentance.split(\"<mask>\")[0]\n",
        "    second_part = sentance.split(\"<mask>\")[1]\n",
        "    merged_sentance = f\"{first_part} {nlp.tokenizer.mask_token} {second_part}\"\n",
        "    result = nlp(merged_sentance)\n",
        "\n",
        "    for i, r in enumerate(result):\n",
        "        print(f\"Predicions {i}: score={r['score']:.2f} -> {r['sequence']}\")\n"
      ],
      "metadata": {
        "id": "28qQ-JI_Gv17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_predict(\"Prezydent <mask> wygrał z Trumpem\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTk-8VB6D7df",
        "outputId": "5983164e-6c17-48af-8e64-101751c3e6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicions 0: score=0.31 -> Prezydent Obama wygrał z Trumpem\n",
            "Predicions 1: score=0.25 -> Prezydent Trump wygrał z Trumpem\n",
            "Predicions 2: score=0.07 -> Prezydent USA wygrał z Trumpem\n",
            "Predicions 3: score=0.04 -> Prezydent Clinton wygrał z Trumpem\n",
            "Predicions 4: score=0.04 -> Prezydent Bush wygrał z Trumpem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "tokenizer_roberta = AutoTokenizer.from_pretrained('xlm-roberta-large')\n",
        "model_roberta = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-large\")\n"
      ],
      "metadata": {
        "id": "ttKbZsMPNPl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qd1knQeOt1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XLM-RoBERTa (large-sized model)\n",
        "\n",
        "RoBERTa is a transformers model pretrained on a large corpus in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts."
      ],
      "metadata": {
        "id": "2JdKvkvNOucG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def roberta_predict(sentance):\n",
        "    nlp = pipeline('fill-mask', model=\"xlm-roberta-large\")\n",
        "    result = nlp(sentance)\n",
        "\n",
        "    for i, r in enumerate(result):\n",
        "        print(f\"Predicions {i}: score={r['score']:.2f} -> {r['sequence']}\")\n"
      ],
      "metadata": {
        "id": "dV2G3g9aNxwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roberta_predict(\"Prezydent <mask> wygrał z Trumpem\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9kYZA_cODSX",
        "outputId": "5c119968-a861-443f-de10-c8838e90624f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicions 0: score=0.17 -> Prezydent Peru wygrał z Trumpem\n",
            "Predicions 1: score=0.17 -> Prezydent Putin wygrał z Trumpem\n",
            "Predicions 2: score=0.11 -> Prezydent Obama wygrał z Trumpem\n",
            "Predicions 3: score=0.04 -> Prezydent Macron wygrał z Trumpem\n",
            "Predicions 4: score=0.04 -> Prezydent USA wygrał z Trumpem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations\n",
        "TwHIN-BERT is a new multi-lingual Tweet language model that is trained on 7 billion Tweets from over 100 distinct languages. TwHIN-BERT differs from prior pre-trained language models as it is trained with not only text-based self-supervision (e.g., MLM), but also with a social objective based on the rich social engagements within a Twitter Heterogeneous Information Network (TwHIN).\n",
        "\n",
        "TwHIN-BERT can be used as a drop-in replacement for BERT in a variety of NLP and recommendation tasks. It not only outperforms similar models semantic understanding tasks such text classification), but also social recommendation tasks such as predicting user to Tweet engagement."
      ],
      "metadata": {
        "id": "69vtBy6hR5rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def twhin_bert(sentance):\n",
        "    nlp = pipeline('fill-mask', model='Twitter/twhin-bert-base')\n",
        "    result = nlp(sentance)\n",
        "    for i, r in enumerate(result):\n",
        "        print(f\"Predicions {i}: score={r['score']:.2f} -> {r['sequence']}\")\n"
      ],
      "metadata": {
        "id": "o4bwJttjRe8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twhin_bert(\"Prezydent <mask> wygrał z Trumpem\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l4t5aYMRgtD",
        "outputId": "f2c45746-00d5-47f6-ae3a-5c54fbe4e136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicions 0: score=0.40 -> Prezydent USA wygrał z Trumpem\n",
            "Predicions 1: score=0.19 -> Prezydent Warszawy wygrał z Trumpem\n",
            "Predicions 2: score=0.12 -> Prezydent Polski wygrał z Trumpem\n",
            "Predicions 3: score=0.03 -> Prezydent RP wygrał z Trumpem\n",
            "Predicions 4: score=0.03 -> Prezydent Trump wygrał z Trumpem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Devise a method to test if the langage model understands Polish cases. E.g. testing for nominal case could be expressed as \"Warszawa to największe [MASK]\", and the masked word should be in nominative case. Create sentences for each case."
      ],
      "metadata": {
        "id": "3u7Z2we3SBe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mianownik:\n",
        "print(\"bert_predict\")\n",
        "bert_predict(\"Warszawa to największe <mask>\")\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(\"Warszawa to największe <mask>\")\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(\"Warszawa to największe <mask>\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgseMcVwSvZy",
        "outputId": "beb45284-7043-4159-ddd4-be4628572204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.92 -> Warszawa to największe miasto\n",
            "Predicions 1: score=0.01 -> Warszawa to największe.\n",
            "Predicions 2: score=0.01 -> Warszawa to największe miejsce\n",
            "Predicions 3: score=0.01 -> Warszawa to największe województwo\n",
            "Predicions 4: score=0.01 -> Warszawa to największe lotnisko\n",
            "roberta_predict\n",
            "Predicions 0: score=0.95 -> Warszawa to największe miasto\n",
            "Predicions 1: score=0.03 -> Warszawa to największe miasta\n",
            "Predicions 2: score=0.01 -> Warszawa to największe centrum\n",
            "Predicions 3: score=0.00 -> Warszawa to największe Miasto\n",
            "Predicions 4: score=0.00 -> Warszawa to największe...\n",
            "twhin_bert\n",
            "Predicions 0: score=0.09 -> Warszawa to największe miasto\n",
            "Predicions 1: score=0.07 -> Warszawa to największe święto\n",
            "Predicions 2: score=0.06 -> Warszawa to największe szczęście\n",
            "Predicions 3: score=0.06 -> Warszawa to największe życie\n",
            "Predicions 4: score=0.04 -> Warszawa to największe miejsce\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dopełniacz:\n",
        "print(\"bert_predict\")\n",
        "bert_predict(\"Mój dom jest naprzeciwko <mask>, więc chodzimy tam robić zakupy\")\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(\"Mój dom jest naprzeciwko <mask>, więc chodzimy tam robić zakupy\")\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(\"Mój dom jest naprzeciwko <mask>, więc chodzimy tam robić zakupy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGMkVV6TTVSd",
        "outputId": "10eaefc9-3565-47fd-d7ec-e8d0f57f4d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.09 -> Mój dom jest naprzeciwko mnie, więc chodzimy tam robić zakupy\n",
            "Predicions 1: score=0.06 -> Mój dom jest naprzeciwko domu, więc chodzimy tam robić zakupy\n",
            "Predicions 2: score=0.05 -> Mój dom jest naprzeciwko szkoły, więc chodzimy tam robić zakupy\n",
            "Predicions 3: score=0.03 -> Mój dom jest naprzeciwko kościoła, więc chodzimy tam robić zakupy\n",
            "Predicions 4: score=0.03 -> Mój dom jest naprzeciwko plaży, więc chodzimy tam robić zakupy\n",
            "roberta_predict\n",
            "Predicions 0: score=0.66 -> Mój dom jest naprzeciwko sklepu, więc chodzimy tam robić zakupy\n",
            "Predicions 1: score=0.14 -> Mój dom jest naprzeciwko Tesco, więc chodzimy tam robić zakupy\n",
            "Predicions 2: score=0.03 -> Mój dom jest naprzeciwko rynku, więc chodzimy tam robić zakupy\n",
            "Predicions 3: score=0.02 -> Mój dom jest naprzeciwko Lidl, więc chodzimy tam robić zakupy\n",
            "Predicions 4: score=0.01 -> Mój dom jest naprzeciwko szkoły, więc chodzimy tam robić zakupy\n",
            "twhin_bert\n",
            "Predicions 0: score=0.09 -> Mój dom jest naprzeciwko otwarte, więc chodzimy tam robić zakupy\n",
            "Predicions 1: score=0.02 -> Mój dom jest naprzeciwko duży, więc chodzimy tam robić zakupy\n",
            "Predicions 2: score=0.02 -> Mój dom jest naprzeciwko blisko, więc chodzimy tam robić zakupy\n",
            "Predicions 3: score=0.02 -> Mój dom jest naprzeciwkony, więc chodzimy tam robić zakupy\n",
            "Predicions 4: score=0.02 -> Mój dom jest naprzeciwkoły, więc chodzimy tam robić zakupy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# celownik:\n",
        "print(\"bert_predict\")\n",
        "bert_predict(\"Zapomniałem kupić mojej <mask> prezentu na Walentynki.\")\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(\"Zapomniałem kupić mojej <mask> prezentu na Walentynki.\")\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(\"Zapomniałem kupić mojej <mask> prezentu na Walentynki.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKOIuUHuUjyc",
        "outputId": "00e691ad-e8cc-4702-89d6-292d8d82c8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.36 -> Zapomniałem kupić mojej mamie prezentu na Walentynki.\n",
            "Predicions 1: score=0.19 -> Zapomniałem kupić mojej żonie prezentu na Walentynki.\n",
            "Predicions 2: score=0.13 -> Zapomniałem kupić mojej dziewczynie prezentu na Walentynki.\n",
            "Predicions 3: score=0.08 -> Zapomniałem kupić mojej matce prezentu na Walentynki.\n",
            "Predicions 4: score=0.05 -> Zapomniałem kupić mojej córce prezentu na Walentynki.\n",
            "roberta_predict\n",
            "Predicions 0: score=0.33 -> Zapomniałem kupić mojej mami prezentu na Walentynki.\n",
            "Predicions 1: score=0.28 -> Zapomniałem kupić mojej mamy prezentu na Walentynki.\n",
            "Predicions 2: score=0.12 -> Zapomniałem kupić mojej Kasi prezentu na Walentynki.\n",
            "Predicions 3: score=0.05 -> Zapomniałem kupić mojej Mamy prezentu na Walentynki.\n",
            "Predicions 4: score=0.04 -> Zapomniałem kupić mojej pani prezentu na Walentynki.\n",
            "twhin_bert\n",
            "Predicions 0: score=0.86 -> Zapomniałem kupić mojej mamy prezentu na Walentynki.\n",
            "Predicions 1: score=0.02 -> Zapomniałem kupić mojej pani prezentu na Walentynki.\n",
            "Predicions 2: score=0.01 -> Zapomniałem kupić mojej mama prezentu na Walentynki.\n",
            "Predicions 3: score=0.01 -> Zapomniałem kupić mojej mami prezentu na Walentynki.\n",
            "Predicions 4: score=0.01 -> Zapomniałem kupić mojej rodziny prezentu na Walentynki.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# biernik:\n",
        "print(\"bert_predict\")\n",
        "bert_predict(\"Lubię czarną <mask>.\")\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(\"Lubię czarną <mask>.\")\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(\"Lubię czarną <mask>.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhkZjo_yVbZ0",
        "outputId": "c0800cfa-d0f9-4349-8ecc-f6afe2d06f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.11 -> Lubię czarną muzykę.\n",
            "Predicions 1: score=0.10 -> Lubię czarną kawę.\n",
            "Predicions 2: score=0.07 -> Lubię czarną skórę.\n",
            "Predicions 3: score=0.05 -> Lubię czarną magię.\n",
            "Predicions 4: score=0.04 -> Lubię czarną kobietę.\n",
            "roberta_predict\n",
            "Predicions 0: score=0.32 -> Lubię czarną skórę.\n",
            "Predicions 1: score=0.03 -> Lubię czarną stronę.\n",
            "Predicions 2: score=0.03 -> Lubię czarną noc.\n",
            "Predicions 3: score=0.03 -> Lubię czarną miłość.\n",
            "Predicions 4: score=0.03 -> Lubię czarną wodę.\n",
            "twhin_bert\n",
            "Predicions 0: score=0.16 -> Lubię czarną kąpiel.\n",
            "Predicions 1: score=0.11 -> Lubię czarną wodę.\n",
            "Predicions 2: score=0.10 -> Lubię czarną twarz.\n",
            "Predicions 3: score=0.06 -> Lubię czarną biały.\n",
            "Predicions 4: score=0.04 -> Lubię czarną osobę.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Narzędnik:\n",
        "print(\"bert_predict\")\n",
        "bert_predict(\"Interesuję się <mask>, więc czytam wiele książek\")\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(\"Interesuję się <mask>, więc czytam wiele książek\")\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(\"Interesuję się <mask>, więc czytam wiele książek\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQn7W1qdWdMz",
        "outputId": "6db8acaa-61a1-46ce-d601-78524dfb09d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.13 -> Interesuję się sztuką, więc czytam wiele książek\n",
            "Predicions 1: score=0.07 -> Interesuję się muzyką, więc czytam wiele książek\n",
            "Predicions 2: score=0.05 -> Interesuję się nauką, więc czytam wiele książek\n",
            "Predicions 3: score=0.05 -> Interesuję się tym, więc czytam wiele książek\n",
            "Predicions 4: score=0.05 -> Interesuję się historią, więc czytam wiele książek\n",
            "roberta_predict\n",
            "Predicions 0: score=0.14 -> Interesuję się fantasy, więc czytam wiele książek\n",
            "Predicions 1: score=0.14 -> Interesuję się wszystkim, więc czytam wiele książek\n",
            "Predicions 2: score=0.07 -> Interesuję się wiedzą, więc czytam wiele książek\n",
            "Predicions 3: score=0.06 -> Interesuję się literatura, więc czytam wiele książek\n",
            "Predicions 4: score=0.05 -> Interesuję się dziećmi, więc czytam wiele książek\n",
            "twhin_bert\n",
            "Predicions 0: score=0.16 -> Interesuję się książek, więc czytam wiele książek\n",
            "Predicions 1: score=0.13 -> Interesuję się książki, więc czytam wiele książek\n",
            "Predicions 2: score=0.09 -> Interesuję się przeczytać, więc czytam wiele książek\n",
            "Predicions 3: score=0.03 -> Interesuję się pracować, więc czytam wiele książek\n",
            "Predicions 4: score=0.02 -> Interesuję się przyjaciół, więc czytam wiele książek\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# miejscownik:\n",
        "print(\"bert_predict\")\n",
        "bert_predict(\"O mojej <mask> wolałbym nie rozmawiać.\")\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(\"O mojej <mask> wolałbym nie rozmawiać.\")\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(\"O mojej <mask> wolałbym nie rozmawiać.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2Iap2yDbN3g",
        "outputId": "7d1042d2-f960-4266-dd76-a3fa5b61d51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.14 -> O mojej żonie wolałbym nie rozmawiać.\n",
            "Predicions 1: score=0.10 -> O mojej pracy wolałbym nie rozmawiać.\n",
            "Predicions 2: score=0.09 -> O mojej rodzinie wolałbym nie rozmawiać.\n",
            "Predicions 3: score=0.06 -> O mojej przyszłości wolałbym nie rozmawiać.\n",
            "Predicions 4: score=0.06 -> O mojej śmierci wolałbym nie rozmawiać.\n",
            "roberta_predict\n",
            "Predicions 0: score=0.16 -> O mojej pracy wolałbym nie rozmawiać.\n",
            "Predicions 1: score=0.11 -> O mojej przyszłości wolałbym nie rozmawiać.\n",
            "Predicions 2: score=0.09 -> O mojej przeszłości wolałbym nie rozmawiać.\n",
            "Predicions 3: score=0.07 -> O mojej sytuacji wolałbym nie rozmawiać.\n",
            "Predicions 4: score=0.07 -> O mojej opinii wolałbym nie rozmawiać.\n",
            "twhin_bert\n",
            "Predicions 0: score=0.16 -> O mojej głowie wolałbym nie rozmawiać.\n",
            "Predicions 1: score=0.09 -> O mojej pracy wolałbym nie rozmawiać.\n",
            "Predicions 2: score=0.09 -> O mojej przyszłości wolałbym nie rozmawiać.\n",
            "Predicions 3: score=0.04 -> O mojej szkole wolałbym nie rozmawiać.\n",
            "Predicions 4: score=0.04 -> O mojej wolności wolałbym nie rozmawiać.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wolacz:\n",
        "print(\"bert_predict\")\n",
        "bert_predict(\"Szanowna Pani <mask> !\")\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(\"Szanowna Pani <mask> !\")\n",
        "\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(\"Szanowna Pani <mask> !\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtg4r2_Gcy91",
        "outputId": "c7366ec7-e2ab-49a9-f940-277c1dad58f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.81 -> Szanowna Pani Marszałek!\n",
            "Predicions 1: score=0.07 -> Szanowna Pani Minister!\n",
            "Predicions 2: score=0.07 -> Szanowna Pani Poseł!\n",
            "Predicions 3: score=0.02 -> Szanowna Pani Premier!\n",
            "Predicions 4: score=0.01 -> Szanowna Pani Prezes!\n",
            "roberta_predict\n",
            "Predicions 0: score=0.22 -> Szanowna Panie!\n",
            "Predicions 1: score=0.18 -> Szanowna Pani Dyrektor!\n",
            "Predicions 2: score=0.17 -> Szanowna Pani Prezes!\n",
            "Predicions 3: score=0.07 -> Szanowna Pani Minister!\n",
            "Predicions 4: score=0.03 -> Szanowna Pani Doktor!\n",
            "twhin_bert\n",
            "Predicions 0: score=0.70 -> Szanowna Panie!\n",
            "Predicions 1: score=0.03 -> Szanowna Pani Merkel!\n",
            "Predicions 2: score=0.02 -> Szanowna Panią!\n",
            "Predicions 3: score=0.02 -> Szanowna Pani Ukraina!\n",
            "Predicions 4: score=0.01 -> Szanowna Pani Boże!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4wb_JTXmftJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Devise a method to test long-range relationships such as gender. E.e. you can use two verbs where withe masculine and feminine gender, where one of the verbs is masked. Both verbs should have the same gender, assuming the subject is the same. Define at least 3 such sentences."
      ],
      "metadata": {
        "id": "7O8Rqs0Pfz54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test:\n",
        "sentance = \"Dawno nie widziałem się z rodziami, mama <mask> na wakacje a tata pracuje. \"\n",
        "print(\"bert_predict\")\n",
        "bert_predict(sentance)\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(sentance)\n",
        "\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(sentance)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdDsme__gb9m",
        "outputId": "79d319a7-06f2-4495-87e1-758bb5c53c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.32 -> Dawno nie widziałem się z rodziami, mama wyjechała na wakacje a tata pracuje.\n",
            "Predicions 1: score=0.31 -> Dawno nie widziałem się z rodziami, mama wyjeżdża na wakacje a tata pracuje.\n",
            "Predicions 2: score=0.12 -> Dawno nie widziałem się z rodziami, mama przyjeżdża na wakacje a tata pracuje.\n",
            "Predicions 3: score=0.08 -> Dawno nie widziałem się z rodziami, mama jedzie na wakacje a tata pracuje.\n",
            "Predicions 4: score=0.07 -> Dawno nie widziałem się z rodziami, mama pojechała na wakacje a tata pracuje.\n",
            "roberta_predict\n",
            "Predicions 0: score=0.41 -> Dawno nie widziałem się z rodziami, mama była na wakacje a tata pracuje.\n",
            "Predicions 1: score=0.28 -> Dawno nie widziałem się z rodziami, mama jest na wakacje a tata pracuje.\n",
            "Predicions 2: score=0.10 -> Dawno nie widziałem się z rodziami, mama idzie na wakacje a tata pracuje.\n",
            "Predicions 3: score=0.06 -> Dawno nie widziałem się z rodziami, mama wychodzi na wakacje a tata pracuje.\n",
            "Predicions 4: score=0.04 -> Dawno nie widziałem się z rodziami, mama jeździ na wakacje a tata pracuje.\n",
            "twhin_bert\n",
            "Predicions 0: score=0.54 -> Dawno nie widziałem się z rodziami, mama idzie na wakacje a tata pracuje.\n",
            "Predicions 1: score=0.09 -> Dawno nie widziałem się z rodziami, mama jest na wakacje a tata pracuje.\n",
            "Predicions 2: score=0.05 -> Dawno nie widziałem się z rodziami, mama chce na wakacje a tata pracuje.\n",
            "Predicions 3: score=0.04 -> Dawno nie widziałem się z rodziami, mama wraca na wakacje a tata pracuje.\n",
            "Predicions 4: score=0.03 -> Dawno nie widziałem się z rodziami, mama wchodzi na wakacje a tata pracuje.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test:\n",
        "sentance = \"Umyłem  buty żony, bo <mask> je biegając. \"\n",
        "print(\"bert_predict\")\n",
        "bert_predict(sentance)\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(sentance)\n",
        "\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(sentance)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yEayB6_hCWh",
        "outputId": "063a93c3-3c34-4231-9dc9-7c85ce9b84fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.09 -> Umyłem buty żony, bo nosiła je biegając.\n",
            "Predicions 1: score=0.04 -> Umyłem buty żony, bo znalazłem je biegając.\n",
            "Predicions 2: score=0.04 -> Umyłem buty żony, bo zgubiłem je biegając.\n",
            "Predicions 3: score=0.04 -> Umyłem buty żony, bo miała je biegając.\n",
            "Predicions 4: score=0.03 -> Umyłem buty żony, bo straciłem je biegając.\n",
            "roberta_predict\n",
            "Predicions 0: score=0.28 -> Umyłem buty żony, bo nosi je biegając.\n",
            "Predicions 1: score=0.07 -> Umyłem buty żony, bo spala je biegając.\n",
            "Predicions 2: score=0.06 -> Umyłem buty żony, bo pali je biegając.\n",
            "Predicions 3: score=0.04 -> Umyłem buty żony, bo miała je biegając.\n",
            "Predicions 4: score=0.04 -> Umyłem buty żony, bo zakłada je biegając.\n",
            "twhin_bert\n",
            "Predicions 0: score=0.10 -> Umyłem buty żony, bo lubię je biegając.\n",
            "Predicions 1: score=0.09 -> Umyłem buty żony, bo mam je biegając.\n",
            "Predicions 2: score=0.05 -> Umyłem buty żony, bo miałem je biegając.\n",
            "Predicions 3: score=0.04 -> Umyłem buty żony, bo widzę je biegając.\n",
            "Predicions 4: score=0.03 -> Umyłem buty żony, bo kupił je biegając.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test:\n",
        "sentance = \"Syn chodził na zajęcia, mimo tego nauczycielka  nie <mask> go do kolejnej klasy. \"\n",
        "print(\"bert_predict\")\n",
        "bert_predict(sentance)\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(sentance)\n",
        "\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(sentance)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKQt3Hp-iF0j",
        "outputId": "80d173b0-97de-4c3e-ff04-a05de4c7e88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.17 -> Syn chodził na zajęcia, mimo tego nauczycielka nie chciała go do kolejnej klasy.\n",
            "Predicions 1: score=0.12 -> Syn chodził na zajęcia, mimo tego nauczycielka nie zabrała go do kolejnej klasy.\n",
            "Predicions 2: score=0.09 -> Syn chodził na zajęcia, mimo tego nauczycielka nie wysłała go do kolejnej klasy.\n",
            "Predicions 3: score=0.06 -> Syn chodził na zajęcia, mimo tego nauczycielka nie oddała go do kolejnej klasy.\n",
            "Predicions 4: score=0.05 -> Syn chodził na zajęcia, mimo tego nauczycielka nie przeniosła go do kolejnej klasy.\n",
            "roberta_predict\n",
            "Predicions 0: score=0.16 -> Syn chodził na zajęcia, mimo tego nauczycielka nie wprowadza go do kolejnej klasy.\n",
            "Predicions 1: score=0.09 -> Syn chodził na zajęcia, mimo tego nauczycielka nie chciała go do kolejnej klasy.\n",
            "Predicions 2: score=0.08 -> Syn chodził na zajęcia, mimo tego nauczycielka nie wysyła go do kolejnej klasy.\n",
            "Predicions 3: score=0.05 -> Syn chodził na zajęcia, mimo tego nauczycielka nie oddaje go do kolejnej klasy.\n",
            "Predicions 4: score=0.04 -> Syn chodził na zajęcia, mimo tego nauczycielka nie przyjmuje go do kolejnej klasy.\n",
            "twhin_bert\n",
            "Predicions 0: score=0.24 -> Syn chodził na zajęcia, mimo tego nauczycielka nie wysyła go do kolejnej klasy.\n",
            "Predicions 1: score=0.22 -> Syn chodził na zajęcia, mimo tego nauczycielka nie chciała go do kolejnej klasy.\n",
            "Predicions 2: score=0.10 -> Syn chodził na zajęcia, mimo tego nauczycielka nie zaprosi go do kolejnej klasy.\n",
            "Predicions 3: score=0.09 -> Syn chodził na zajęcia, mimo tego nauczycielka nie zaprasza go do kolejnej klasy.\n",
            "Predicions 4: score=0.04 -> Syn chodził na zajęcia, mimo tego nauczycielka nie ma go do kolejnej klasy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check if the model captures real-world knolwedge. For instance a sentence \"[MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\" checks if the model \"knows\" the description of water. Define at least 3 such sentences."
      ],
      "metadata": {
        "id": "xPzYmsVVjOXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentance = \"<mask> wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\"\n",
        "\n",
        "print(\"bert_predict\")\n",
        "bert_predict(sentance)\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(sentance)\n",
        "\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(sentance)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUFAGNdTjNrQ",
        "outputId": "d8325a0d-92e7-482b-f563-7d7cf13a65f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.21 -> Woda wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 1: score=0.07 -> Słońce wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 2: score=0.06 -> Nie wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 3: score=0.06 -> Ziemia wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 4: score=0.05 -> Piwo wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "roberta_predict\n",
            "Predicions 0: score=0.06 -> Olej wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 1: score=0.05 -> Sól wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 2: score=0.03 -> śnieg wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 3: score=0.03 -> Alkohol wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 4: score=0.03 -> Metal wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "twhin_bert\n",
            "Predicions 0: score=0.10 -> Ukraina wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 1: score=0.09 -> Putin wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 2: score=0.07 -> Polska wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 3: score=0.02 -> Merkel wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n",
            "Predicions 4: score=0.02 -> Świat wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentance = \"Satelitą Ziemi jest <mask>\"\n",
        "\n",
        "print(\"bert_predict\")\n",
        "bert_predict(sentance)\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(sentance)\n",
        "\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(sentance)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiPl8NmmjgOc",
        "outputId": "0e8bb19d-dba1-4440-9ead-0865928837ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.48 -> Satelitą Ziemi jest :\n",
            "Predicions 1: score=0.02 -> Satelitą Ziemi jest.\n",
            "Predicions 2: score=0.02 -> Satelitą Ziemi jest Ziemia\n",
            "Predicions 3: score=0.02 -> Satelitą Ziemi jest satelita\n",
            "Predicions 4: score=0.01 -> Satelitą Ziemi jest Księżyc\n",
            "roberta_predict\n",
            "Predicions 0: score=0.44 -> Satelitą Ziemi jest...\n",
            "Predicions 1: score=0.34 -> Satelitą Ziemi jest:\n",
            "Predicions 2: score=0.04 -> Satelitą Ziemi jest...\n",
            "Predicions 3: score=0.02 -> Satelitą Ziemi jest.\n",
            "Predicions 4: score=0.01 -> Satelitą Ziemi jest NASA\n",
            "twhin_bert\n",
            "Predicions 0: score=0.09 -> Satelitą Ziemi jest.\n",
            "Predicions 1: score=0.06 -> Satelitą Ziemi jest Polska\n",
            "Predicions 2: score=0.04 -> Satelitą Ziemi jest Putin\n",
            "Predicions 3: score=0.03 -> Satelitą Ziemi jest...\n",
            "Predicions 4: score=0.02 -> Satelitą Ziemi jest Bóg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentance = \"Chrzest Polski był w <mask> roku\"\n",
        "\n",
        "print(\"bert_predict\")\n",
        "bert_predict(sentance)\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(sentance)\n",
        "\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(sentance)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN2mNy9Ok8Bx",
        "outputId": "daaf789d-ce61-4ece-cf5b-05e255aa3244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.03 -> Chrzest Polski był w 1921 roku\n",
            "Predicions 1: score=0.03 -> Chrzest Polski był w 1945 roku\n",
            "Predicions 2: score=0.02 -> Chrzest Polski był w 1946 roku\n",
            "Predicions 3: score=0.02 -> Chrzest Polski był w 1918 roku\n",
            "Predicions 4: score=0.02 -> Chrzest Polski był w 1939 roku\n",
            "roberta_predict\n",
            "Predicions 0: score=0.11 -> Chrzest Polski był w 1918 roku\n",
            "Predicions 1: score=0.06 -> Chrzest Polski był w 1939 roku\n",
            "Predicions 2: score=0.03 -> Chrzest Polski był w 1989 roku\n",
            "Predicions 3: score=0.02 -> Chrzest Polski był w 1914 roku\n",
            "Predicions 4: score=0.02 -> Chrzest Polski był w 1991 roku\n",
            "twhin_bert\n",
            "Predicions 0: score=0.09 -> Chrzest Polski był w 2015 roku\n",
            "Predicions 1: score=0.06 -> Chrzest Polski był w 2008 roku\n",
            "Predicions 2: score=0.05 -> Chrzest Polski był w 2014 roku\n",
            "Predicions 3: score=0.05 -> Chrzest Polski był w tym roku\n",
            "Predicions 4: score=0.05 -> Chrzest Polski był w 2019 roku\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentance = \"Jeżeli zamrozisz wodę to zamienia się w  <mask>\"\n",
        "\n",
        "print(\"bert_predict\")\n",
        "bert_predict(sentance)\n",
        "\n",
        "print(\"roberta_predict\")\n",
        "roberta_predict(sentance)\n",
        "\n",
        "\n",
        "print(\"twhin_bert\")\n",
        "twhin_bert(sentance)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBWB-2WFjmCZ",
        "outputId": "399df151-eac2-48f9-f0df-3825ed2d0001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_predict\n",
            "Predicions 0: score=0.09 -> Jeżeli zamrozisz wodę to zamienia się w wodę\n",
            "Predicions 1: score=0.07 -> Jeżeli zamrozisz wodę to zamienia się w kamień\n",
            "Predicions 2: score=0.04 -> Jeżeli zamrozisz wodę to zamienia się w lód\n",
            "Predicions 3: score=0.04 -> Jeżeli zamrozisz wodę to zamienia się w krew\n",
            "Predicions 4: score=0.02 -> Jeżeli zamrozisz wodę to zamienia się w wino\n",
            "roberta_predict\n",
            "Predicions 0: score=0.14 -> Jeżeli zamrozisz wodę to zamienia się w alkohol\n",
            "Predicions 1: score=0.08 -> Jeżeli zamrozisz wodę to zamienia się w gaz\n",
            "Predicions 2: score=0.05 -> Jeżeli zamrozisz wodę to zamienia się w wodę\n",
            "Predicions 3: score=0.04 -> Jeżeli zamrozisz wodę to zamienia się w tłuszcz\n",
            "Predicions 4: score=0.04 -> Jeżeli zamrozisz wodę to zamienia się w cukier\n",
            "twhin_bert\n",
            "Predicions 0: score=0.06 -> Jeżeli zamrozisz wodę to zamienia się w wodę\n",
            "Predicions 1: score=0.03 -> Jeżeli zamrozisz wodę to zamienia się w życie\n",
            "Predicions 2: score=0.02 -> Jeżeli zamrozisz wodę to zamienia się w prąd\n",
            "Predicions 3: score=0.02 -> Jeżeli zamrozisz wodę to zamienia się w pis\n",
            "Predicions 4: score=0.02 -> Jeżeli zamrozisz wodę to zamienia się w chleb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ORj5HcJTkdSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the following questions:\n",
        "Which of the models produced the best results?\n",
        "- najlepsze wyniki zawsze daje Polish Bert\n",
        "\n",
        "Was any of the models able to capture Polish grammar?\n",
        "- wszystkie dobrze sobie radzily z gramatyka\n",
        "\n",
        "Was any of the models able to capture long-distant relationships between the words?\n",
        "- Polish-bert i Robert\n",
        "\n",
        "Was any of the models able to capture world knowledge?\n",
        "- jedyne opprawne sygestie dał Polish Bert ale równiez nie ma dobrey knowledge-base\n",
        "\n",
        "What are the most striking errors made by the models?\n",
        "- twhin_bert nie radził sobie z rozumieniem ogólnego kontekstu"
      ],
      "metadata": {
        "id": "7IrbvA9hkvdT"
      }
    }
  ]
}