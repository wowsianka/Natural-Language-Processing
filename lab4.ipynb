{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6350d7-66cb-42cb-9415-bdc357e1a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.pl import Polish\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ec1ce-3936-46ba-a960-1d7fe5115d67",
   "metadata": {},
   "source": [
    "## zadanie 1. Use SpaCy tokenizer API to tokenize the text from the law corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee682fb-7369-490e-9523-8856a49ae16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Polish()\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43116eec-3e9a-4047-8c1f-6d2b4c46cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "for file in os.listdir('./ustawy'):\n",
    "    file_names.append(file)\n",
    "\n",
    "file_names.remove('.DS_Store')\n",
    "# file_names.remove('.ipynb_checkpoints')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1946992-df29-4a61-a4e9-af8ef7dc2f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data_tokenize():\n",
    "    tok_data = []\n",
    "    for filename in file_names:\n",
    "        with open(\"ustawy\" + '/' + filename, 'r') as file:\n",
    "            content = file.read()\n",
    "            tokens = tokenizer(content)\n",
    "            tok_data.append([filename, tokens])\n",
    "    return tok_data\n",
    "\n",
    "tokenized_data = read_data_tokenize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bca16b8f-1a8a-4f3f-8368-2987b3694407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[254]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649be96-3b42-4def-9c7b-66e0b5722be3",
   "metadata": {},
   "source": [
    "## zadanie 2. Compute bigram counts of downcased tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0230d180-a902-4265-adf4-8a0db7a55047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "bigrams =  collections.defaultdict(lambda: 0)\n",
    "def count_freq_for_bigrams(tokens):\n",
    "    for i in range(0, len(tokens) -1):\n",
    "        word_1, word_2 = tokens[i], tokens[i + 1]\n",
    "        bigrams[(word_1, word_2)] += 1\n",
    "    # return bigrams\n",
    "\n",
    "\n",
    "for doc in tokenized_data:\n",
    "    tokens = []\n",
    "    for token in doc[1]:\n",
    "        tokens.append(token.text.lower())\n",
    "    count_freq_for_bigrams(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c3e94d-3ea7-4506-bacc-b4596332f798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('\\n\\n\\n\\n', 'dz'), 836),\n",
       " (('dz', '.'), 8885),\n",
       " (('.', 'u'), 8016),\n",
       " (('u', '.'), 8134),\n",
       " (('.', 'z'), 5017),\n",
       " (('z', '2001'), 902),\n",
       " (('2001', 'r'), 1883),\n",
       " (('r', '.'), 33015),\n",
       " (('.', 'nr'), 20321),\n",
       " (('nr', '81'), 83)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "870a6ab6-b125-4ea7-a360-3cf7bc56cdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('art', '.'), 83778),\n",
       " (('ust', '.'), 53552),\n",
       " (('.', '\\n'), 49741),\n",
       " (('poz', '.'), 45198),\n",
       " ((',', 'poz'), 39655),\n",
       " (('-', '-'), 36542),\n",
       " (('r', '.'), 33015),\n",
       " (('w', 'art'), 30170),\n",
       " (('.', '1'), 29734),\n",
       " ((',', 'o'), 28739)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_sorted = sorted(bigrams.items(), key=lambda x: x[1], reverse=True)\n",
    "bigrams_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d4d81-dc94-490f-a569-866b2290d212",
   "metadata": {},
   "source": [
    "## zadanie 3. Discard bigrams containing characters other than letters. Make sure that you discard the invalid entries after computing the bigram counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5e6dc-0ae3-4b68-a57e-63463320c05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f012a843-9a0c-4cc6-b870-23933c022e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('z', 'dnia'), 8989),\n",
       " (('o', 'zmianie'), 1176),\n",
       " (('zmianie', 'ustawy'), 829),\n",
       " (('ustawy', 'o'), 1394),\n",
       " (('o', 'państwowej'), 70),\n",
       " (('państwowej', 'straży'), 474),\n",
       " (('straży', 'pożarnej'), 425),\n",
       " (('w', 'ustawie'), 4777),\n",
       " (('ustawie', 'z'), 3624),\n",
       " (('i', 'nr'), 7871)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_if_letter(bigrams):\n",
    "    bigrams_filtered = dict(filter(lambda a: a[0][0].isalpha() and a[0][1].isalpha(), bigrams.items()))\n",
    "    return bigrams_filtered\n",
    "\n",
    "bigrams_filtered = check_if_letter(bigrams)\n",
    "list(bigrams_filtered.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a098e0-4480-4aa8-b2b8-3cb646353304",
   "metadata": {},
   "source": [
    "## zadanie 4. Use pointwise mutual information to compute the measure for all pairs of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6dc5117-a497-4964-b81c-b2939097e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word_freq_list = collections.defaultdict(int)\n",
    "for doc in tokenized_data:\n",
    "    for token in doc[1]:\n",
    "        single_word_freq_list[token.text.lower()] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5074c51c-ce8a-4002-b3ec-bf8d3e860b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('z', 'dnia'), 4.425845728993178),\n",
       " (('o', 'zmianie'), 5.103554204317643),\n",
       " (('zmianie', 'ustawy'), 6.352299503962667),\n",
       " (('ustawy', 'o'), 3.118470454737466),\n",
       " (('o', 'państwowej'), 2.204872755045761)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def get_pointwise_mutual_information(bigrams, single_word_freq_list):\n",
    "    bigrams_pmi = {}\n",
    "    word_len = sum(bigrams.values())\n",
    "    word_len2 = sum(single_word_freq_list.values())\n",
    "    for item in bigrams.items():\n",
    "        bigram = item[0]\n",
    "        count = item[1]\n",
    "        bigrams_pmi[bigram] = math.log((count/word_len) / ((single_word_freq_list[bigram[0]]/word_len2) * (single_word_freq_list[bigram[1]]/word_len2)))\n",
    "    return bigrams_pmi\n",
    "\n",
    "bigrams_pmi = get_pointwise_mutual_information(bigrams_filtered, single_word_freq_list)\n",
    "list(bigrams_pmi.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a16b35-797d-4e21-a2d2-172b1673aaa8",
   "metadata": {},
   "source": [
    "## zadanie 5. Sort the word pairs according to that measure in the descending order and determine top 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a265673-1d13-46bf-981d-326a04deb29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doktorów', 'habilitowanych'),\n",
       " ('pionową', 'ścianę'),\n",
       " ('usprawnianie', 'zaburzonych'),\n",
       " ('gałki', 'ocznej'),\n",
       " ('stępkę', 'położono'),\n",
       " ('wybuchła', 'wojna'),\n",
       " ('dało', 'pożytecznego'),\n",
       " ('poświęcenie', 'objęło'),\n",
       " ('błędem', 'nautycznym'),\n",
       " ('pobudzających', 'innowacyjność')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_pmi_bigrmams = dict(sorted(bigrams_pmi.items(), key=lambda item: item[1], reverse=True))\n",
    "list(sorted_pmi_bigrmams)[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539f178-a2af-412b-bbed-f05249bd2a58",
   "metadata": {},
   "source": [
    "## zadanie 6. Filter bigrams with number of occurrences lower than 5. Determine top 10 entries for the remaining dataset (>=5 occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21851ff-e94d-461f-bf74-a809234e24dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ręcznego', 'miotacza'),\n",
       " ('stajnią', 'wyścigową'),\n",
       " ('świeckie', 'przygotowujące'),\n",
       " ('klęskami', 'żywiołowymi'),\n",
       " ('obcowania', 'płciowego'),\n",
       " ('grzegorz', 'schetyna'),\n",
       " ('młynki', 'młotkowe'),\n",
       " ('młyny', 'kulowe'),\n",
       " ('otworami', 'wiertniczymi'),\n",
       " ('środa', 'wlkp')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_feq_5 = dict(filter(lambda x: bigrams_filtered[x[0]] >= 5, sorted_pmi_bigrmams.items()))\n",
    "list(bigrams_feq_5)[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9a46f-7ef3-452e-93db-18fe4668e76a",
   "metadata": {},
   "source": [
    "## zadanie 7. Use KRNNT or Clarin-PL API(https://ws.clarin-pl.eu/tager.shtml) to tag and lemmatize the corpus.\n",
    "## zadanie 8 Using the tagged corpus compute bigram statistic for the tokens containing: a. lemmatized, downcased word b. morphosyntactic category of the word (subst, fin, adj, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07c0e287-1977-4e88-a70a-78f83e077b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3907778e-05bb-4a76-9272-08200d1ace56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_single_word_freq_list = collections.defaultdict(int)\n",
    "for doc in tokenized_data:\n",
    "    for token in doc[1]:\n",
    "        single_word_freq_list[token.text.lower()] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6c5fe86-9963-4212-96d9-57268790e0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz\n",
      "brev\n"
     ]
    }
   ],
   "source": [
    "with open(f'./Clarin_result/ustawy%1993_646.txt', \"r\", encoding='utf-8') as f:\n",
    "        content = parse(f)\n",
    " \n",
    "for token in content.getElementsByTagName(\"tok\"):\n",
    "    word = token.getElementsByTagName(\"orth\")[0].firstChild.nodeValue.lower()\n",
    "    category = token.getElementsByTagName(\"ctag\")[0].firstChild.nodeValue.split(':')[0].lower()\n",
    "    print(word)\n",
    "    print(category)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72eaf1e4-d86f-49f6-9d93-f1456829a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "clarin_tokenizer = {}\n",
    "base_form_freq = defaultdict(lambda: 0)\n",
    "clarin_bigram_freq = defaultdict(lambda: 0)\n",
    "clarin_trigram_freq = defaultdict(lambda: 0)\n",
    "\n",
    "for file in os.listdir(\"./Clarin_output/\"):\n",
    "    tokens=[]\n",
    "    with open(f'./Clarin_output/{file}', \"r\", encoding='utf-8') as f:\n",
    "        content = parse(f)\n",
    " \n",
    "    for token in content.getElementsByTagName(\"tok\"):\n",
    "        word = token.getElementsByTagName(\"orth\")[0].firstChild.nodeValue.lower()\n",
    "        base_form = token.getElementsByTagName(\"base\")[0].firstChild.nodeValue.lower()\n",
    "        category = token.getElementsByTagName(\"ctag\")[0].firstChild.nodeValue.split(':')[0].lower()\n",
    "        tokens.append(base_form + ':' + category)\n",
    "        \n",
    "        clarin_tokenizer[word] = {\"base_form\": base_form , \"category\": category}\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.split(':')[0].isalpha():\n",
    "            base_form_freq[token] += 1\n",
    "    \n",
    "    for i in range(0, len(tokens) -1):\n",
    "        word_1, word_2 = tokens[i].split(':')[0], tokens[i + 1].split(':')[0]\n",
    "        cat_1, cat_2 = tokens[i].split(':')[1], tokens[i + 1].split(':')[1]\n",
    "        if word_1.isalpha() and word_2.isalpha():\n",
    "            clarin_bigram_freq[(word_1+\":\"+ cat_1, word_2+\":\"+ cat_2)] += 1\n",
    "    \n",
    "    for i in range(0, len(tokens) -2):\n",
    "        word_1, word_2, word_3 = tokens[i].split(':')[0], tokens[i + 1].split(':')[0], tokens[i + 2].split(':')[0]\n",
    "        cat_1, cat_2, cat_3 = tokens[i].split(':')[1], tokens[i + 1].split(':')[1], tokens[i + 2].split(':')[1]\n",
    "        if word_1.isalpha() and word_2.isalpha() and word_3.isalpha():\n",
    "            clarin_trigram_freq[(word_1+\":\"+ cat_1, word_2+\":\"+ cat_2, word_3+\":\"+ cat_3)] += 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2028ab1d-9bca-4606-a6be-b9369a699468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('u:prep', 'sekunda:brev'), 141),\n",
       " (('sekunda:brev', 't:ign'), 142),\n",
       " (('t:ign', 'a:conj'), 141),\n",
       " (('a:conj', 'w:prep'), 2182),\n",
       " (('w:prep', 'a:conj'), 145),\n",
       " (('a:conj', 'z:prep'), 163),\n",
       " (('z:prep', 'dzień:subst'), 11360),\n",
       " (('o:prep', 'służba:subst'), 187),\n",
       " (('służba:subst', 'wojskowy:adj'), 948),\n",
       " (('wojskowy:adj', 'żołnierz:subst'), 71)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clarin_bigram_freq.items())[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f56d4f86-fd37-4c8d-838b-5adfa3ab26f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dz', {'base_form': 'dzieje_(apostolskie)', 'category': 'brev'}),\n",
       " ('.', {'base_form': '.', 'category': 'interp'}),\n",
       " ('u', {'base_form': 'u', 'category': 'prep'}),\n",
       " ('z', {'base_form': 'z', 'category': 'prep'}),\n",
       " ('2003', {'base_form': '2003', 'category': 'num'}),\n",
       " ('r', {'base_form': 'r', 'category': 'ign'}),\n",
       " ('nr', {'base_form': 'nr', 'category': 'subst'}),\n",
       " ('179', {'base_form': '179', 'category': 'num'}),\n",
       " (',', {'base_form': ',', 'category': 'interp'}),\n",
       " ('poz', {'base_form': 'poz', 'category': 'ign'})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clarin_tokenizer.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c6418d8-1bc3-4315-bb97-fa9be5b11856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u:prep', 9155),\n",
       " ('z:prep', 87991),\n",
       " ('r:ign', 33192),\n",
       " ('nr:subst', 44953),\n",
       " ('poz:ign', 45245),\n",
       " ('sekunda:brev', 378),\n",
       " ('t:ign', 491),\n",
       " ('a:conj', 17189),\n",
       " ('w:prep', 202950),\n",
       " ('dzień:subst', 26990)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(base_form_freq.items())[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9794e26-19a3-4440-91f7-f4f1fe5d54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_without_cat = dict((word.split(':')[0], freq) for word, freq in base_form_freq.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd078683-8b14-43ef-9cab-0f89a4b65b74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## zadanie 10. Compute the same statistics as for the non-lemmatized words (i.e. PMI) and print top-10 entries with at least 5 occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02071ee7-ea80-4bed-8d1e-4fd02ab4df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pointwise_mutual_information_cl(bigrams, single_word_freq_list):\n",
    "    bigrams_pmi = {}\n",
    "    word_len = sum(bigrams.values())\n",
    "    word_len2 = sum(single_word_freq_list.values())\n",
    "    for item in bigrams.items():\n",
    "        bigram = item[0]\n",
    "        w_1, w_2 = bigram[0], bigram[1]\n",
    "        count = item[1]\n",
    "        bigrams_pmi[bigram] = math.log((count/word_len) / ((single_word_freq_list[w_1]/word_len2) * (single_word_freq_list[w_2]/word_len2)))\n",
    "    return bigrams_pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df20f817-8bce-47a2-8ee8-f3aeb74d0e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('u:prep', 'sekunda:brev'), 5.241951508048575),\n",
       " (('sekunda:brev', 't:ign'), 8.174630004585758),\n",
       " (('t:ign', 'a:conj'), 4.350432109654096),\n",
       " (('a:conj', 'w:prep'), 1.0653985911964208),\n",
       " (('w:prep', 'a:conj'), -1.6458648327760208),\n",
       " (('a:conj', 'z:prep'), -0.693123267625648),\n",
       " (('z:prep', 'dzień:subst'), 3.0997834411588387),\n",
       " (('o:prep', 'służba:subst'), 0.8751060702927494),\n",
       " (('służba:subst', 'wojskowy:adj'), 6.053530302072146),\n",
       " (('wojskowy:adj', 'żołnierz:subst'), 4.351183449375892),\n",
       " (('żołnierz:subst', 'zawodowy:adj'), 6.0609895987446665),\n",
       " (('zawodowy:adj', 'rozdział:subst'), -0.9477194222519562),\n",
       " (('przepis:subst', 'ogólny:adj'), 3.9198821970505406),\n",
       " (('ogólny:adj', 'art:ign'), 2.3310995977519786),\n",
       " (('ustawa:subst', 'określać:fin'), 2.7389455107174054)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_clarin = get_pointwise_mutual_information_cl(clarin_bigram_freq, base_form_freq)\n",
    "list(bigrams_clarin.items())[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "388413a1-75b9-40c3-9393-21fc7f4d5cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('atrakcyjny:adj', 'turystycznie:adv'), 15.350141270398606),\n",
       " (('niepeł:ign', 'nosprawności:ign'), 15.350141270398606),\n",
       " (('dzonej:ign', 'obdukcja:subst'), 15.350141270398606),\n",
       " (('inwestycy:ign', 'jnych:ign'), 15.350141270398606),\n",
       " (('okr:ign', 'eśl:ign'), 15.350141270398606),\n",
       " (('pos:ign', 'taca:subst'), 15.350141270398606),\n",
       " (('zwi:ign', 'ązk:ign'), 15.350141270398606),\n",
       " (('ier:ign', 'ają:ign'), 15.350141270398606),\n",
       " (('ają:ign', 'cyc:subst'), 15.350141270398606),\n",
       " (('potasowyc:ign', 'atmosfe:ign'), 15.350141270398606)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_clarin_sorted = sorted(bigrams_clarin.items(), key=lambda x: x[1], reverse=True)\n",
    "bigrams_clarin_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "048b6982-dd77-4909-b174-c40289db3b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('młynek:subst', 'młotkowy:adj'), 13.740703357964506),\n",
       " (('grzegorz:subst', 'schetyna:ign'), 13.740703357964506),\n",
       " (('teryto:ign', 'rialnego:ign'), 13.740703357964506),\n",
       " (('pasta:subst', 'emulsyjny:adj'), 13.558381801170551),\n",
       " (('chrom:subst', 'sześciowartościowy:adj'), 13.558381801170551),\n",
       " (('odpowiedzieć:fin', 'dzialności:ign'), 13.558381801170551),\n",
       " (('adam:subst', 'mickiewicz:subst'), 13.558381801170551),\n",
       " (('łańcuchowa:subst', 'rozszczepienie:subst'), 13.558381801170551),\n",
       " (('młyn:subst', 'kulowy:adj'), 13.404231121343292),\n",
       " (('piotrek:subst', 'trybunalski:adj'), 13.404231121343292)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_bigrams_feq_5 = dict(filter(lambda x: clarin_bigram_freq[x[0]] >= 5, dict(bigrams_clarin_sorted).items()))\n",
    "list(cl_bigrams_feq_5.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4faf56-0f77-4fd7-8e3a-ef1ced2a725a",
   "metadata": {},
   "source": [
    "## Compute trigram counts for both corpora and perform the same filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b677b7-e7ca-470e-b82a-e96a96248702",
   "metadata": {},
   "source": [
    "## Use PMI (with 5 occurrence threshold) to compute top 10 results for the trigrams. Devise a method for computing the values, based on the results for bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3c9e03-d97c-4a75-b359-b57827b3b033",
   "metadata": {},
   "source": [
    "#### Non-lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c1895c1-9c7e-45b5-82c5-a02795c65a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "trigrams =  collections.defaultdict(lambda: 0)\n",
    "def count_freq_for_trigrams(tokens):\n",
    "    for i in range(0, len(tokens) -2):\n",
    "        word_1, word_2, word_3 = tokens[i], tokens[i + 1], tokens[i + 2]\n",
    "        trigrams[(word_1, word_2, word_3)] += 1\n",
    "    # return bigrams\n",
    "\n",
    "\n",
    "for doc in tokenized_data:\n",
    "    tokens = []\n",
    "    for token in doc[1]:\n",
    "        tokens.append(token.text.lower())\n",
    "    count_freq_for_trigrams(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95d9881e-74d3-4cb3-a3db-7fb8e6e32ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('o', 'zmianie', 'ustawy'), 750),\n",
       " (('zmianie', 'ustawy', 'o'), 614),\n",
       " (('ustawy', 'o', 'państwowej'), 9),\n",
       " (('o', 'państwowej', 'straży'), 26),\n",
       " (('państwowej', 'straży', 'pożarnej'), 368),\n",
       " (('w', 'ustawie', 'z'), 3347),\n",
       " (('ustawie', 'z', 'dnia'), 3511),\n",
       " (('przez', 'osoby', 'prawne'), 19),\n",
       " (('osoby', 'prawne', 'lub'), 28),\n",
       " (('prawne', 'lub', 'fizyczne'), 14)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_if_letter_trig(trigrams):\n",
    "    return dict(filter(lambda a: a[0][0].isalpha() and a[0][1].isalpha() and a[0][2].isalpha() and a[1] > 4, trigrams.items()))\n",
    "\n",
    "trigrams_filtered = check_if_letter_trig(trigrams)\n",
    "list(trigrams_filtered.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5d89c2c-6e0b-41c4-9266-0dec2eab11fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('o', 'zmianie', 'ustawy'), 11.917562387155579),\n",
       " (('zmianie', 'ustawy', 'o'), 11.717484108772364),\n",
       " (('ustawy', 'o', 'państwowej'), 7.417411195098773),\n",
       " (('o', 'państwowej', 'straży'), 10.551863596004043),\n",
       " (('państwowej', 'straży', 'pożarnej'), 18.071950413420815)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pointwise_mutual_information_tr(trigrams, single_word_freq_list):\n",
    "    trigrams_pmi = {}\n",
    "    word_sum = sum(trigrams.values())\n",
    "    word_len2 = sum(single_word_freq_list.values())\n",
    "    for item in trigrams.items():\n",
    "        trigrams = item[0]\n",
    "        count = item[1]\n",
    "        trigrams_pmi[trigrams] = math.log((count/word_sum) / ((single_word_freq_list[trigrams[0]]/word_len2)* (single_word_freq_list[trigrams[2]]/word_len2) * (single_word_freq_list[trigrams[1]]/word_len2)))\n",
    "    return trigrams_pmi\n",
    "\n",
    "trigrams_pmi = get_pointwise_mutual_information_tr(trigrams_filtered, single_word_freq_list)\n",
    "list(trigrams_pmi.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a725afb-b01b-4261-a459-2fc65ff7188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('profilem', 'zaufanym', 'epuap'), 27.971678329747785),\n",
       " (('finałowego', 'turnieju', 'mistrzostw'), 27.7079494983185),\n",
       " (('przedwczesnego', 'wyrębu', 'drzewostanu'), 27.5876521436954),\n",
       " (('potwierdzonym', 'profilem', 'zaufanym'), 27.505177331053254),\n",
       " (('piłce', 'nożnej', 'uefa'), 27.464592050938176),\n",
       " (('cienką', 'sierścią', 'zwierzęcą'), 27.222678396941976),\n",
       " (('szybkiemu', 'postępowi', 'technicznemu'), 27.177732685237856),\n",
       " (('turnieju', 'mistrzostw', 'europy'), 27.17732124725633),\n",
       " (('grożącą', 'jemu', 'samemu'), 27.01033677866058),\n",
       " (('wypalonym', 'paliwem', 'jądrowym'), 26.959043484273028)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_pmi_trigrmams = dict(sorted(trigrams_pmi.items(), key=lambda item: item[1], reverse=True))\n",
    "list(sorted_pmi_trigrmams.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c7143-4ebf-4ff0-8eec-aefa8c62c3f3",
   "metadata": {},
   "source": [
    "### Lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72866721-f361-4a67-a88c-e35fe9c6e450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('u:prep', 'sekunda:brev', 't:ign'), 141),\n",
       " (('sekunda:brev', 't:ign', 'a:conj'), 141),\n",
       " (('t:ign', 'a:conj', 'w:prep'), 141),\n",
       " (('a:conj', 'w:prep', 'a:conj'), 141),\n",
       " (('w:prep', 'a:conj', 'z:prep'), 141),\n",
       " (('a:conj', 'z:prep', 'dzień:subst'), 144),\n",
       " (('o:prep', 'służba:subst', 'wojskowy:adj'), 52),\n",
       " (('służba:subst', 'wojskowy:adj', 'żołnierz:subst'), 70),\n",
       " (('wojskowy:adj', 'żołnierz:subst', 'zawodowy:adj'), 61),\n",
       " (('żołnierz:subst', 'zawodowy:adj', 'rozdział:subst'), 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clarin_trigram_freq.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc24bf09-6b8a-4438-9218-fa291be6b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pointwise_mutual_information_cl_tr(bigrams, single_word_freq_list):\n",
    "    bigrams_pmi = {}\n",
    "    word_len = sum(bigrams.values())\n",
    "    word_len2 = sum(single_word_freq_list.values())\n",
    "    for item in bigrams.items():\n",
    "        bigram = item[0]\n",
    "        w_1, w_2, w_3 = bigram[0], bigram[1], bigram[2]\n",
    "        count = item[1]\n",
    "        bigrams_pmi[bigram] = math.log((count/word_len) / ((single_word_freq_list[w_1]/word_len2) * (single_word_freq_list[w_3]/word_len2) *  (single_word_freq_list[w_2]/word_len2)))\n",
    "    return bigrams_pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "837ab9a0-fb77-4b55-982c-2bbf30540653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('u:prep', 'sekunda:brev', 't:ign'), 14.339852685157055),\n",
       " (('sekunda:brev', 't:ign', 'a:conj'), 13.70988321893751),\n",
       " (('t:ign', 'a:conj', 'w:prep'), 7.424062492290052),\n",
       " (('a:conj', 'w:prep', 'a:conj'), 3.868481696756416),\n",
       " (('w:prep', 'a:conj', 'z:prep'), 2.235516804581714),\n",
       " (('a:conj', 'z:prep', 'dzień:subst'), 4.27406343003454),\n",
       " (('o:prep', 'służba:subst', 'wojskowy:adj'), 7.365565061716466),\n",
       " (('służba:subst', 'wojskowy:adj', 'żołnierz:subst'), 11.004400063911579),\n",
       " (('wojskowy:adj', 'żołnierz:subst', 'zawodowy:adj'), 11.289324323261507),\n",
       " (('żołnierz:subst', 'zawodowy:adj', 'rozdział:subst'), 6.60900959979314),\n",
       " (('przepis:subst', 'ogólny:adj', 'art:ign'), 7.7920371215914574),\n",
       " (('zasada:subst', 'powoływać:ger', 'do:prep'), 5.6103149255066285),\n",
       " (('powoływać:ger', 'do:prep', 'zawodowy:adj'), 6.795406744961749),\n",
       " (('do:prep', 'zawodowy:adj', 'służba:subst'), 6.78730953472913),\n",
       " (('zawodowy:adj', 'służba:subst', 'wojskowy:adj'), 12.305279846269096)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_clarin = get_pointwise_mutual_information_cl_tr(clarin_trigram_freq, base_form_freq)\n",
    "list(trigrams_clarin.items())[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ee235932-b124-4266-b63c-72c685988939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ier:ign', 'ają:ign', 'cyc:subst'), 30.23921067580649),\n",
       " (('dofinansować:ger', 'podlegać:fin', 'zwro:ign'), 30.23921067580649),\n",
       " (('wywołać:inf', 'niedziedzicznewrodzone:ign', 'deformacja:subst'),\n",
       "  30.23921067580649),\n",
       " (('wszywać:ger', 'zamek:subst', 'błyskawiczny:adj'), 30.23921067580649),\n",
       " (('chwi:ign', 'lą:ign', 'uprawomocnić:ger'), 30.23921067580649),\n",
       " (('zabezpieczyć:ppas', 'wpi:ign', 'sem:subst'), 30.23921067580649),\n",
       " (('mink:ign', 'virus:ign', 'enteritis:ign'), 30.23921067580649),\n",
       " (('hos:ign', 'pic:subst', 'juma:subst'), 30.23921067580649),\n",
       " (('benzimidazol:ign', 'leonotis:ign', 'leonurus:ign'), 30.23921067580649),\n",
       " (('hostilis:ign', 'mitragyna:ign', 'speciosa:ign'), 30.23921067580649)]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_clarin_sorted = sorted(trigrams_clarin.items(), key=lambda x: x[1], reverse=True)\n",
    "trigrams_clarin_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1b3fe34d-2327-4f07-89aa-71feb429933e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('móc:fin', 'być:inf', 'udzielać:ppas'), 29.84152770814038),\n",
       " (('bez:prep', 'uzyskać:ger', 'wymagać:ppas'), 29.546063495246543),\n",
       " (('najwyższy:subst', 'pozostawiać:fin', 'bez:prep'), 29.322919943932334),\n",
       " (('móc:fin', 'być:inf', 'przyznawać:ppas'), 29.299203417315017),\n",
       " (('móc:fin', 'być:inf', 'przekazywać:ppas'), 29.299203417315017),\n",
       " (('móc:fin', 'być:inf', 'tworzyć:ppas'), 29.076059866000808),\n",
       " (('móc:fin', 'być:inf', 'używać:ppas'), 28.913540936503033),\n",
       " (('móc:fin', 'być:inf', 'wykorzystać:ppas'), 28.788377793549028),\n",
       " (('móc:praet', 'by:qub', 'wywołać:inf'), 28.743717022721604),\n",
       " (('móc:fin', 'być:inf', 'przeznaczyć:ppas'), 28.670594757892644)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_trigrams_feq_5 = dict(filter(lambda x: clarin_trigram_freq[x[0]] >= 5, dict(trigrams_clarin_sorted).items()))\n",
    "list(cl_trigrams_feq_5.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c499e-5dab-4b03-a105-23685fcecad6",
   "metadata": {},
   "source": [
    "## Create a table comparing the results for copora without and with tagging and lemmatization (separate table for bigrams and trigrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "80e96e59-6f33-414e-b625-f60bf05826af",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_1 = pd.DataFrame(([bigrams[0], bigrams[1], freq] for  bigrams, freq in bigrams_feq_5.items()),\n",
    "             columns = ['not_Lemmatized_word_1', 'not_Lemmatized_word_2', 'pmi_1']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a8ad7811-e426-42d9-92ae-e7dd80526b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_2 = pd.DataFrame(([bigrams[0], bigrams[1], freq] for  bigrams, freq in cl_bigrams_feq_5.items()),\n",
    "             columns = ['Lemmatized_word_1', 'Lemmatized_word_2', 'pmi_2']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b362dbd2-4482-4c80-bcef-269fa744ae43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_Lemmatized_word_1</th>\n",
       "      <th>not_Lemmatized_word_2</th>\n",
       "      <th>pmi_1</th>\n",
       "      <th>Lemmatized_word_1</th>\n",
       "      <th>Lemmatized_word_2</th>\n",
       "      <th>pmi_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ręcznego</td>\n",
       "      <td>miotacza</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>18.454768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stajnią</td>\n",
       "      <td>wyścigową</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>uczestniczyć:inf</td>\n",
       "      <td>18.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>świeckie</td>\n",
       "      <td>przygotowujące</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>zamawiać:pact</td>\n",
       "      <td>przekazywać:fin</td>\n",
       "      <td>18.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klęskami</td>\n",
       "      <td>żywiołowymi</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>bez:prep</td>\n",
       "      <td>uzyskać:ger</td>\n",
       "      <td>18.075690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obcowania</td>\n",
       "      <td>płciowego</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>żądać:inf</td>\n",
       "      <td>17.942158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grzegorz</td>\n",
       "      <td>schetyna</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>zorganizować:ppas</td>\n",
       "      <td>część:subst</td>\n",
       "      <td>17.852546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>młynki</td>\n",
       "      <td>młotkowe</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>dokonany:adj</td>\n",
       "      <td>bez:prep</td>\n",
       "      <td>17.719015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>młyny</td>\n",
       "      <td>kulowe</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>pozostawiać:fin</td>\n",
       "      <td>bez:prep</td>\n",
       "      <td>17.719015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>otworami</td>\n",
       "      <td>wiertniczymi</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>wchodzić:inf</td>\n",
       "      <td>17.564864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>środa</td>\n",
       "      <td>wlkp</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>bez:prep</td>\n",
       "      <td>usprawiedliwić:ppas</td>\n",
       "      <td>17.564864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zaszkodzić</td>\n",
       "      <td>wynikom</td>\n",
       "      <td>14.828082</td>\n",
       "      <td>sprawdzić:ger</td>\n",
       "      <td>uzyskać:ppas</td>\n",
       "      <td>17.564864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adama</td>\n",
       "      <td>mickiewicza</td>\n",
       "      <td>14.645760</td>\n",
       "      <td>podlegać:fin</td>\n",
       "      <td>zaopiniować:ger</td>\n",
       "      <td>17.564864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>przeponowe</td>\n",
       "      <td>rurowe</td>\n",
       "      <td>14.645760</td>\n",
       "      <td>podlegać:pact</td>\n",
       "      <td>sprawdzić:ger</td>\n",
       "      <td>17.477853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>odczynów</td>\n",
       "      <td>poszczepiennych</td>\n",
       "      <td>14.645760</td>\n",
       "      <td>bez:prep</td>\n",
       "      <td>wymagać:ppas</td>\n",
       "      <td>17.410713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diagności</td>\n",
       "      <td>laboratoryjni</td>\n",
       "      <td>14.645760</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>podlegać:inf</td>\n",
       "      <td>17.277182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mleczka</td>\n",
       "      <td>makowego</td>\n",
       "      <td>14.645760</td>\n",
       "      <td>podlegać:fin</td>\n",
       "      <td>przywrócić:ger</td>\n",
       "      <td>17.277182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>piotrków</td>\n",
       "      <td>trybunalski</td>\n",
       "      <td>14.491609</td>\n",
       "      <td>zamawiać:pact</td>\n",
       "      <td>żądać:fin</td>\n",
       "      <td>17.277182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chwytów</td>\n",
       "      <td>obezwładniających</td>\n",
       "      <td>14.491609</td>\n",
       "      <td>zamawiać:pact</td>\n",
       "      <td>informować:fin</td>\n",
       "      <td>17.277182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>papierem</td>\n",
       "      <td>wartościowym</td>\n",
       "      <td>14.491609</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>tworzyć:inf</td>\n",
       "      <td>17.159399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>klęską</td>\n",
       "      <td>żywiołową</td>\n",
       "      <td>14.491609</td>\n",
       "      <td>bez:prep</td>\n",
       "      <td>przeprowadzać:ger</td>\n",
       "      <td>17.094860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not_Lemmatized_word_1 not_Lemmatized_word_2      pmi_1  Lemmatized_word_1  \\\n",
       "0               ręcznego              miotacza  14.828082            móc:fin   \n",
       "1                stajnią             wyścigową  14.828082            móc:fin   \n",
       "2               świeckie        przygotowujące  14.828082      zamawiać:pact   \n",
       "3               klęskami           żywiołowymi  14.828082           bez:prep   \n",
       "4              obcowania             płciowego  14.828082            móc:fin   \n",
       "5               grzegorz              schetyna  14.828082  zorganizować:ppas   \n",
       "6                 młynki              młotkowe  14.828082       dokonany:adj   \n",
       "7                  młyny                kulowe  14.828082    pozostawiać:fin   \n",
       "8               otworami          wiertniczymi  14.828082            móc:fin   \n",
       "9                  środa                  wlkp  14.828082           bez:prep   \n",
       "10            zaszkodzić               wynikom  14.828082      sprawdzić:ger   \n",
       "11                 adama           mickiewicza  14.645760       podlegać:fin   \n",
       "12            przeponowe                rurowe  14.645760      podlegać:pact   \n",
       "13              odczynów       poszczepiennych  14.645760           bez:prep   \n",
       "14             diagności         laboratoryjni  14.645760            móc:fin   \n",
       "15               mleczka              makowego  14.645760       podlegać:fin   \n",
       "16              piotrków           trybunalski  14.491609      zamawiać:pact   \n",
       "17               chwytów     obezwładniających  14.491609      zamawiać:pact   \n",
       "18              papierem          wartościowym  14.491609            móc:fin   \n",
       "19                klęską             żywiołową  14.491609           bez:prep   \n",
       "\n",
       "      Lemmatized_word_2      pmi_2  \n",
       "0               być:inf  18.454768  \n",
       "1      uczestniczyć:inf  18.171000  \n",
       "2       przekazywać:fin  18.171000  \n",
       "3           uzyskać:ger  18.075690  \n",
       "4             żądać:inf  17.942158  \n",
       "5           część:subst  17.852546  \n",
       "6              bez:prep  17.719015  \n",
       "7              bez:prep  17.719015  \n",
       "8          wchodzić:inf  17.564864  \n",
       "9   usprawiedliwić:ppas  17.564864  \n",
       "10         uzyskać:ppas  17.564864  \n",
       "11      zaopiniować:ger  17.564864  \n",
       "12        sprawdzić:ger  17.477853  \n",
       "13         wymagać:ppas  17.410713  \n",
       "14         podlegać:inf  17.277182  \n",
       "15       przywrócić:ger  17.277182  \n",
       "16            żądać:fin  17.277182  \n",
       "17       informować:fin  17.277182  \n",
       "18          tworzyć:inf  17.159399  \n",
       "19    przeprowadzać:ger  17.094860  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_df = pd.concat((bigram_1, bigram_2), axis=1)\n",
    "bigrams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "42cb0fe9-259c-4c8e-8f84-6a9a847ad83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_1 = pd.DataFrame(([trigrams[0], trigrams[1],trigrams[2], freq] for  trigrams, freq in sorted_pmi_trigrmams.items()),\n",
    "             columns = ['not_Lemmatized_word_1', 'not_Lemmatized_word_2','not_Lemmatized_word_3', 'pmi_1']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c0416fb2-630d-463f-9e4b-52740df70b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_2 = pd.DataFrame(([trigrams[0], trigrams[1],trigrams[2], freq] for  trigrams, freq in cl_trigrams_feq_5.items()),\n",
    "             columns = ['Lemmatized_word_1', 'Lemmatized_word_2','Lemmatized_word_3', 'pmi_2']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "531d2f38-b911-42d8-a47c-c4dffd0b39b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_Lemmatized_word_1</th>\n",
       "      <th>not_Lemmatized_word_2</th>\n",
       "      <th>not_Lemmatized_word_3</th>\n",
       "      <th>pmi_1</th>\n",
       "      <th>Lemmatized_word_1</th>\n",
       "      <th>Lemmatized_word_2</th>\n",
       "      <th>Lemmatized_word_3</th>\n",
       "      <th>pmi_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>profilem</td>\n",
       "      <td>zaufanym</td>\n",
       "      <td>epuap</td>\n",
       "      <td>27.971678</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>udzielać:ppas</td>\n",
       "      <td>29.841528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finałowego</td>\n",
       "      <td>turnieju</td>\n",
       "      <td>mistrzostw</td>\n",
       "      <td>27.707949</td>\n",
       "      <td>bez:prep</td>\n",
       "      <td>uzyskać:ger</td>\n",
       "      <td>wymagać:ppas</td>\n",
       "      <td>29.546063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>przedwczesnego</td>\n",
       "      <td>wyrębu</td>\n",
       "      <td>drzewostanu</td>\n",
       "      <td>27.587652</td>\n",
       "      <td>najwyższy:subst</td>\n",
       "      <td>pozostawiać:fin</td>\n",
       "      <td>bez:prep</td>\n",
       "      <td>29.322920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>potwierdzonym</td>\n",
       "      <td>profilem</td>\n",
       "      <td>zaufanym</td>\n",
       "      <td>27.505177</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>przyznawać:ppas</td>\n",
       "      <td>29.299203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>piłce</td>\n",
       "      <td>nożnej</td>\n",
       "      <td>uefa</td>\n",
       "      <td>27.464592</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>przekazywać:ppas</td>\n",
       "      <td>29.299203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cienką</td>\n",
       "      <td>sierścią</td>\n",
       "      <td>zwierzęcą</td>\n",
       "      <td>27.222678</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>tworzyć:ppas</td>\n",
       "      <td>29.076060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>szybkiemu</td>\n",
       "      <td>postępowi</td>\n",
       "      <td>technicznemu</td>\n",
       "      <td>27.177733</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>używać:ppas</td>\n",
       "      <td>28.913541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>turnieju</td>\n",
       "      <td>mistrzostw</td>\n",
       "      <td>europy</td>\n",
       "      <td>27.177321</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>wykorzystać:ppas</td>\n",
       "      <td>28.788378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grożącą</td>\n",
       "      <td>jemu</td>\n",
       "      <td>samemu</td>\n",
       "      <td>27.010337</td>\n",
       "      <td>móc:praet</td>\n",
       "      <td>by:qub</td>\n",
       "      <td>wywołać:inf</td>\n",
       "      <td>28.743717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wypalonym</td>\n",
       "      <td>paliwem</td>\n",
       "      <td>jądrowym</td>\n",
       "      <td>26.959043</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>przeznaczyć:ppas</td>\n",
       "      <td>28.670595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kurtki</td>\n",
       "      <td>anorak</td>\n",
       "      <td>etc</td>\n",
       "      <td>26.912523</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>zmieniać:ppas</td>\n",
       "      <td>28.645277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>zaszkodzić</td>\n",
       "      <td>wynikom</td>\n",
       "      <td>podjętych</td>\n",
       "      <td>26.712369</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>realizować:ppas</td>\n",
       "      <td>28.565234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>poddanych</td>\n",
       "      <td>szybkiemu</td>\n",
       "      <td>postępowi</td>\n",
       "      <td>26.695895</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>zatrudniać:ppas</td>\n",
       "      <td>28.565234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>byłych</td>\n",
       "      <td>hitlerowskich</td>\n",
       "      <td>obozów</td>\n",
       "      <td>26.681081</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>wydawać:ppas</td>\n",
       "      <td>28.522675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mln</td>\n",
       "      <td>dolarów</td>\n",
       "      <td>usa</td>\n",
       "      <td>26.609337</td>\n",
       "      <td>otrzymywać:fin</td>\n",
       "      <td>zawiesić:ppas</td>\n",
       "      <td>część:subst</td>\n",
       "      <td>28.406629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>niepożądanych</td>\n",
       "      <td>odczynów</td>\n",
       "      <td>poszczepiennych</td>\n",
       "      <td>26.602369</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>składować:ppas</td>\n",
       "      <td>28.382913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>religijne</td>\n",
       "      <td>uroczystości</td>\n",
       "      <td>pogrzebowe</td>\n",
       "      <td>26.535229</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>umieścić:ppas</td>\n",
       "      <td>28.382913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dysfunkcji</td>\n",
       "      <td>narządu</td>\n",
       "      <td>wzroku</td>\n",
       "      <td>26.507058</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>sprzedawać:ppas</td>\n",
       "      <td>28.382913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>trwale</td>\n",
       "      <td>zniekształcających</td>\n",
       "      <td>rzeźbę</td>\n",
       "      <td>26.473536</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>przetwarzać:ppas</td>\n",
       "      <td>28.277552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>komunalne</td>\n",
       "      <td>osady</td>\n",
       "      <td>ściekowe</td>\n",
       "      <td>26.438065</td>\n",
       "      <td>móc:fin</td>\n",
       "      <td>być:inf</td>\n",
       "      <td>objąć:ppas</td>\n",
       "      <td>28.072758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not_Lemmatized_word_1 not_Lemmatized_word_2 not_Lemmatized_word_3  \\\n",
       "0               profilem              zaufanym                 epuap   \n",
       "1             finałowego              turnieju            mistrzostw   \n",
       "2         przedwczesnego                wyrębu           drzewostanu   \n",
       "3          potwierdzonym              profilem              zaufanym   \n",
       "4                  piłce                nożnej                  uefa   \n",
       "5                 cienką              sierścią             zwierzęcą   \n",
       "6              szybkiemu             postępowi          technicznemu   \n",
       "7               turnieju            mistrzostw                europy   \n",
       "8                grożącą                  jemu                samemu   \n",
       "9              wypalonym               paliwem              jądrowym   \n",
       "10                kurtki                anorak                   etc   \n",
       "11            zaszkodzić               wynikom             podjętych   \n",
       "12             poddanych             szybkiemu             postępowi   \n",
       "13                byłych         hitlerowskich                obozów   \n",
       "14                   mln               dolarów                   usa   \n",
       "15         niepożądanych              odczynów       poszczepiennych   \n",
       "16             religijne          uroczystości            pogrzebowe   \n",
       "17            dysfunkcji               narządu                wzroku   \n",
       "18                trwale    zniekształcających                rzeźbę   \n",
       "19             komunalne                 osady              ściekowe   \n",
       "\n",
       "        pmi_1 Lemmatized_word_1 Lemmatized_word_2 Lemmatized_word_3      pmi_2  \n",
       "0   27.971678           móc:fin           być:inf     udzielać:ppas  29.841528  \n",
       "1   27.707949          bez:prep       uzyskać:ger      wymagać:ppas  29.546063  \n",
       "2   27.587652   najwyższy:subst   pozostawiać:fin          bez:prep  29.322920  \n",
       "3   27.505177           móc:fin           być:inf   przyznawać:ppas  29.299203  \n",
       "4   27.464592           móc:fin           być:inf  przekazywać:ppas  29.299203  \n",
       "5   27.222678           móc:fin           być:inf      tworzyć:ppas  29.076060  \n",
       "6   27.177733           móc:fin           być:inf       używać:ppas  28.913541  \n",
       "7   27.177321           móc:fin           być:inf  wykorzystać:ppas  28.788378  \n",
       "8   27.010337         móc:praet            by:qub       wywołać:inf  28.743717  \n",
       "9   26.959043           móc:fin           być:inf  przeznaczyć:ppas  28.670595  \n",
       "10  26.912523           móc:fin           być:inf     zmieniać:ppas  28.645277  \n",
       "11  26.712369           móc:fin           być:inf   realizować:ppas  28.565234  \n",
       "12  26.695895           móc:fin           być:inf   zatrudniać:ppas  28.565234  \n",
       "13  26.681081           móc:fin           być:inf      wydawać:ppas  28.522675  \n",
       "14  26.609337    otrzymywać:fin     zawiesić:ppas       część:subst  28.406629  \n",
       "15  26.602369           móc:fin           być:inf    składować:ppas  28.382913  \n",
       "16  26.535229           móc:fin           być:inf     umieścić:ppas  28.382913  \n",
       "17  26.507058           móc:fin           być:inf   sprzedawać:ppas  28.382913  \n",
       "18  26.473536           móc:fin           być:inf  przetwarzać:ppas  28.277552  \n",
       "19  26.438065           móc:fin           być:inf        objąć:ppas  28.072758  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_df = pd.concat((trigram_1, trigram_2), axis=1)\n",
    "trigrams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f7067-2ed1-4dfb-8c6e-3ca41b635ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb4cb6-6ca7-44c0-8340-51115df431a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Why do we have to filter the bigrams, rather than the token sequence?\n",
    " - ze względu na znaki nie alfanumeryczne- jezeli je  usuniemy na poczatku to nie bedzie mialo sensu budowanie bigramow\n",
    "    \n",
    "Which method works better for the bigrams and which for the trigrams?\n",
    "- dla bigramow bez lematyzacji , a trgiramy z \n",
    "\n",
    "What types of expressions are discovered by the methods.\n",
    "- glownie czasowniki, nazwy własne np instytucji\n",
    "\n",
    "Can you devise a different type of filtering that would yield better results?\n",
    "\n",
    "- filtrowanie  wszystkich zaimków"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
